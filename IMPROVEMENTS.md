# IMPROVEMENTS: Почему это лучше, чем просто ChatGPT?

В этом файле описаны ключевые улучшения архитектуры относительно стандартной генерации текста одной LLM (Single-Shot Generation).

## 1. Отсутствие "Каши" в контексте (Role Separation)
В обычном ChatGPT промпт звучит как *"Ты интервьюер, проверяй факты, будь психологом и оценивай кандидата"*. Модель путается, забывает проверить факты или сбивается с тона.
* **В данном проекте**: Каждый агент делает **только одну** вещь, но делает её хорошо. FactChecker не думает о вежливости, он думает только о фактах. Interviewer не думает о фактах, он думает только о формулировке вопроса.

## 2. Скрытое мышление (Hidden Chain-of-Thought)
Обычный бот сразу генерирует ответ. Если пользователь написал чушь, бот может случайно согласиться, чтобы "поддержать беседу".
* **В данном проекте**: Реализован этап **Reflection**. Ментор видит отчет FactChecker'а: *"Кандидат врет"*. Ментор дает команду: *"Не соглашайся. Попроси уточнить"*. Это предотвращает галлюцинации согласия.

## 3. Grounding (Заземление на факты)
Используется **ChromaDB** для векторного поиска по базе знаний.
* **Улучшение**: Агент проверяет ответы не по своей "памяти", а ищет семантически похожие факты в локальной векторной базе. Это позволяет находить релевантную информацию даже если формулировка вопроса отличается от текста в базе.

## 4. Динамическая сложность (Adaptability)
В обычном сценарии бот просто идет по списку вопросов.
* **В данном проекте**: **MentorAgent** получает историю.
    * Если кандидат *Junior* (по ответам) -> Ментор дает команду упростить вопросы.
    * Если кандидат *Senior* -> Ментор командует "Drill down" (копать глубже).
    * Это создает ощущение **реального** живого собеседования, которое подстраивается под уровень собеседника.

## 5. Объективная оценка (Decision Maker)
Оценка происходит не "по ощущениям" последнего сообщения, а на основе **полного лога** с учетом скрытых меток.
* **Пример**: Если кандидат в начале соврал, а потом исправился, DecisionMaker увидит метку `[FactChecker: False]` в начале лога и снизит балл за Hard Skills, даже если в конце всё прошло гладко.

## 6. Использование LangChain (LCEL)
Осуществлен переход от ручной сборки строк к **LangChain Expression Language (LCEL)**.
* **Структура**: Промпты теперь не просто f-strings, а строго типизированные `ChatPromptTemplate`.
* **Пайплайны**: Логика агентов описана как `chain = prompt | llm | output_parser`. Это делает код модульным, легко расширяемым и готовым к внедрению более сложных инструментов (Tools/Function Calling) в будущем.

## 7. Structured Output (Pydantic / JSON Mode)
Вместо парсинга текста регулярками, все агенты возвращают строго типизированные объекты (Pydantic Models).
* **Надежность**: Система не упадет, если LLM забудет поставить запятую в JSON. Валидация происходит автоматически на уровне схемы.

## 8. LLM-as-a-Judge (Самоцензура)
Добавлен отдельный агент-ревизор (**JudgeAgent**), который проверяет ответы интервьюера перед отправкой.
* **Безопасность**: Если основная модель "сорвется" и начнет грубить или галлюцинировать, Судья заблокирует ответ и заставит переписать его.

## 9. Умная Память (Summarization)
Для длинных диалогов реализован механизм сжатия контекста.
* **Эффективность**: Вместо отрезания старых сообщений (как делают простые боты), **SummarizerAgent** переписывает историю в краткое саммари. Агенты всегда помнят суть начала разговора, даже через 50 ходов, потребляя минимум токенов.
